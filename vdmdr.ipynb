{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 5  # Classes 0,1,2,3,4\n",
        "BATCH_SIZE = 2  \n",
        "ACCUMULATION_STEPS = 8 \n",
        "\n",
        "# Memory optimizations\n",
        "torch.cuda.empty_cache()\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,expandable_segments:True'\n",
        "num_epochs = 100  \n",
        "dropout_rate = 0.3  \n",
        "weight_decay = 0.01  \n",
        "patience = 20  \n",
        "min_delta = 0.0001\n",
        "lr_patience = 10 \n",
        "lr_factor = 0.2 \n",
        "fine_tune_learning_rate = 1e-5  \n",
        "\n",
        "# XGBoost parameters\n",
        "xgb_params = {\n",
        "    'max_depth': [6, 8, 10], \n",
        "    'learning_rate': [0.01, 0.03, 0.05], \n",
        "    'n_estimators': [200],  \n",
        "    'min_child_weight': [1, 2],  \n",
        "    'gamma': [0.1, 0.2],  \n",
        "    'subsample': [0.8, 0.9], \n",
        "    'colsample_bytree': [0.8, 0.9],\n",
        "    'tree_method': ['gpu_hist'],\n",
        "    'predictor': ['gpu_predictor'],\n",
        "    'max_bin': [256],\n",
        "    'gpu_id': [0],\n",
        "    'objective': ['multi:softprob'],\n",
        "    'num_class': [num_classes],\n",
        "    'eval_metric': ['mlogloss'],\n",
        "    'use_label_encoder': [False]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Data transforms\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation((-45, 45)),\n",
        "        transforms.ColorJitter(\n",
        "            brightness=0.4, \n",
        "            contrast=0.4, \n",
        "            saturation=0.4, \n",
        "            hue=0.2\n",
        "        ),\n",
        "        transforms.RandomAffine(\n",
        "            degrees=(-30, 30), \n",
        "            translate=(0.15, 0.15), \n",
        "            scale=(0.85, 1.15),\n",
        "            shear=(-10, 10)\n",
        "        ),\n",
        "        transforms.RandomPerspective(p=0.3, distortion_scale=0.5),\n",
        "        transforms.RandomAutocontrast(p=0.3),\n",
        "        transforms.RandomEqualize(p=0.3),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.3),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "        transforms.RandomErasing(p=0.3, scale=(0.02, 0.33))\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Memory optimization\n",
        "import gc\n",
        "\n",
        "def clear_gpu_cache():\n",
        "    \"\"\"Clear GPU cache and garbage collect\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "def get_gpu_memory():\n",
        "    \"\"\"Get current GPU memory usage\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.cuda.memory_allocated() / 1024**2, torch.cuda.memory_reserved() / 1024**2\n",
        "    return 0, 0\n",
        "\n",
        "def print_gpu_memory():\n",
        "    \"\"\"Print current GPU memory usage\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated, reserved = get_gpu_memory()\n",
        "        print(f'GPU Memory: {allocated:.2f}MB allocated, {reserved:.2f}MB reserved')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TwoStreamDataset(Dataset):\n",
        "    def __init__(self, rgb_root, vessel_root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.image_pairs = []\n",
        "        \n",
        "        print(f\"Initializing dataset with RGB root: {rgb_root}\")\n",
        "        print(f\"Vessel root: {vessel_root}\")\n",
        "        \n",
        "        for class_idx in range(5):\n",
        "            class_name = str(class_idx)\n",
        "            rgb_class_dir = os.path.join(rgb_root, class_name)\n",
        "            vessel_class_dir = os.path.join(vessel_root, class_name)\n",
        "            \n",
        "            if not os.path.exists(rgb_class_dir) or not os.path.exists(vessel_class_dir):\n",
        "                print(f\"Warning: Directory not found - RGB: {rgb_class_dir} or Vessel: {vessel_class_dir}\")\n",
        "                continue\n",
        "                \n",
        "            rgb_files = [f for f in os.listdir(rgb_class_dir) if f.endswith('.png')]\n",
        "            \n",
        "            for img_name in rgb_files:\n",
        "                rgb_path = os.path.join(rgb_class_dir, img_name)\n",
        "                vessel_path = os.path.join(vessel_class_dir, img_name)\n",
        "                \n",
        "                if os.path.exists(vessel_path):\n",
        "                    self.image_pairs.append({\n",
        "                        'rgb': rgb_path,\n",
        "                        'vessel': vessel_path,\n",
        "                        'label': class_idx\n",
        "                    })\n",
        "        \n",
        "        print(f\"Total number of image pairs found: {len(self.image_pairs)}\")\n",
        "        if len(self.image_pairs) == 0:\n",
        "            raise RuntimeError(\"No valid image pairs found!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            pair = self.image_pairs[idx]\n",
        "            rgb_img = Image.open(pair['rgb']).convert('RGB')\n",
        "            vessel_img = Image.open(pair['vessel']).convert('RGB')\n",
        "            \n",
        "            if self.transform:\n",
        "                rgb_img = self.transform(rgb_img)\n",
        "                vessel_img = self.transform(vessel_img)\n",
        "            \n",
        "            label = torch.tensor(pair['label'], dtype=torch.long)\n",
        "            return rgb_img, vessel_img, label\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading pair {idx}: {str(e)}\")\n",
        "            print(f\"Paths - RGB: {pair['rgb']}, Vessel: {pair['vessel']}\")\n",
        "            raise e\n",
        "\n",
        "# Dataset\n",
        "print(\"Creating datasets...\")\n",
        "data_dir = \"/kaggle/input/vdmdrneww/New_VDMDR\" \n",
        "rgb_root = os.path.join(data_dir, 'RGB')\n",
        "vessel_root = os.path.join(data_dir, 'Vessel')\n",
        "\n",
        "full_dataset = TwoStreamDataset(rgb_root, vessel_root, transform=data_transforms['train'])\n",
        "\n",
        "# Splits\n",
        "total_len = len(full_dataset)\n",
        "train_len = int(0.7 * total_len)\n",
        "val_len = int(0.15 * total_len)\n",
        "test_len = total_len - train_len - val_len\n",
        "\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, \n",
        "    [train_len, val_len, test_len],\n",
        "    generator=generator\n",
        ")\n",
        "\n",
        "print(f\"Split sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(\n",
        "        train_dataset, \n",
        "        batch_size=BATCH_SIZE, \n",
        "        shuffle=True, \n",
        "        num_workers=2,  \n",
        "        pin_memory=True,  \n",
        "        persistent_workers=True, \n",
        "        prefetch_factor=2 \n",
        "    ),\n",
        "    'val': DataLoader(\n",
        "        val_dataset, \n",
        "        batch_size=BATCH_SIZE, \n",
        "        shuffle=False, \n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True,\n",
        "        prefetch_factor=2\n",
        "    ),\n",
        "    'test': DataLoader(\n",
        "        test_dataset, \n",
        "        batch_size=BATCH_SIZE, \n",
        "        shuffle=False, \n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(train_dataset),\n",
        "    'val': len(val_dataset),\n",
        "    'test': len(test_dataset)\n",
        "}\n",
        "\n",
        "print(\"Dataset sizes:\", dataset_sizes)\n",
        "\n",
        "# Test for first batch\n",
        "print(\"\\nTesting first batch loading...\")\n",
        "try:\n",
        "    train_iter = iter(dataloaders['train'])\n",
        "    first_batch = next(train_iter)\n",
        "    print(\"Successfully loaded first batch!\")\n",
        "    print(f\"RGB tensor shape: {first_batch[0].shape}\")\n",
        "    print(f\"Vessel tensor shape: {first_batch[1].shape}\")\n",
        "    print(f\"Labels shape: {first_batch[2].shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading first batch: {str(e)}\")\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TwoStreamNetwork(nn.Module):\n",
        "    \"\"\"Two-stream neural network with Swin Transformer backbone\"\"\"\n",
        "    def __init__(self, num_classes=5, feature_extraction=False):\n",
        "        super(TwoStreamNetwork, self).__init__()\n",
        "        \n",
        "        # RGB Stream\n",
        "        self.rgb_model = timm.create_model(\n",
        "            'swin_large_patch4_window12_384',  # Swin-L 384x384\n",
        "            pretrained=True,  # Use pretrained weights\n",
        "            use_checkpoint=True,  # Enable gradient checkpointing\n",
        "            checkpoint_path=None,\n",
        "            num_classes=0,  # Remove classification head\n",
        "            drop_path_rate=0.2  # Stochastic depth\n",
        "        )\n",
        "        \n",
        "        # Vessel Stream\n",
        "        self.vessel_model = timm.create_model(\n",
        "            'swin_large_patch4_window12_384',\n",
        "            pretrained=True,\n",
        "            use_checkpoint=True,\n",
        "            checkpoint_path=None,\n",
        "            num_classes=0,\n",
        "            drop_path_rate=0.2\n",
        "        )\n",
        "        \n",
        "        self.rgb_model.set_grad_checkpointing(enable=True)\n",
        "        self.vessel_model.set_grad_checkpointing(enable=True)\n",
        "        \n",
        "        # Feature dimensions\n",
        "        self.feature_dim = 1536\n",
        "        self.combined_features = self.feature_dim * 2\n",
        "        hidden_dim = 1024\n",
        "        \n",
        "        self.feature_extraction = feature_extraction\n",
        "        \n",
        "        if not feature_extraction:\n",
        "            # Fusion Layers\n",
        "            self.fusion = nn.Sequential(\n",
        "                nn.Linear(self.combined_features, hidden_dim),\n",
        "                nn.LayerNorm(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                \n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "                nn.LayerNorm(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                \n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "                nn.LayerNorm(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            )\n",
        "            \n",
        "            # Classification head\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "                nn.LayerNorm(hidden_dim // 2),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim // 2, num_classes)\n",
        "            )\n",
        "            \n",
        "            self._init_weights()\n",
        "                    \n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize the weights of fusion and classifier layers\"\"\"\n",
        "        if not self.feature_extraction:\n",
        "            for m in self.fusion.modules():\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    nn.init.kaiming_normal_(m.weight)\n",
        "                    if m.bias is not None:\n",
        "                        nn.init.zeros_(m.bias)\n",
        "                        \n",
        "            for m in self.classifier.modules():\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    nn.init.kaiming_normal_(m.weight)\n",
        "                    if m.bias is not None:\n",
        "                        nn.init.zeros_(m.bias)\n",
        "                    \n",
        "    @torch.cuda.amp.autocast()\n",
        "    def forward(self, rgb_input, vessel_input):\n",
        "        \"\"\"Forward pass with memory-efficient feature extraction\"\"\"\n",
        "        # Extract RGB features\n",
        "        rgb_features = self.rgb_model(rgb_input)\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        # Extract vessel features\n",
        "        vessel_features = self.vessel_model(vessel_input)\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        # Combine features\n",
        "        combined = torch.cat((rgb_features, vessel_features), dim=1)\n",
        "        \n",
        "        if self.feature_extraction:\n",
        "            return combined\n",
        "        \n",
        "        # Fusion and classification\n",
        "        fused = self.fusion(combined)\n",
        "        output = self.classifier(fused)\n",
        "        \n",
        "        return output\n",
        "\n",
        "# Model initialisation\n",
        "print(\"Creating model...\")\n",
        "model = TwoStreamNetwork(num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(), \n",
        "    lr=fine_tune_learning_rate, \n",
        "    weight_decay=weight_decay,\n",
        "    betas=(0.9, 0.999),  \n",
        "    eps=1e-8  \n",
        ")\n",
        "\n",
        "\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, \n",
        "    mode='min',\n",
        "    factor=lr_factor,\n",
        "    patience=lr_patience,\n",
        "    verbose=True,\n",
        "    min_lr=1e-7\n",
        ")\n",
        "\n",
        "print(\"Model created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n",
        "    \"\"\"Training function with mixed precision, gradient accumulation, and early stopping\"\"\"\n",
        "    since = time.time()\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    \n",
        "    # History\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "    max_grad_norm = 1.0 \n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "        \n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "                \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            \n",
        "            pbar = tqdm(dataloaders[phase], desc=f'{phase} Epoch {epoch}')\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            \n",
        "            for i, (rgb_inputs, vessel_inputs, labels) in enumerate(pbar):\n",
        "                rgb_inputs = rgb_inputs.to(device, non_blocking=True)\n",
        "                vessel_inputs = vessel_inputs.to(device, non_blocking=True)\n",
        "                labels = labels.to(device, non_blocking=True)\n",
        "                \n",
        "                # Forward pass\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    with torch.amp.autocast('cuda'):\n",
        "                        outputs = model(rgb_inputs, vessel_inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        loss = loss / ACCUMULATION_STEPS\n",
        "                    \n",
        "                    # Backward pass (only in training)\n",
        "                    if phase == 'train':\n",
        "                        scaler.scale(loss).backward()\n",
        "                        \n",
        "                        # If we've accumulated enough gradients\n",
        "                        if (i + 1) % ACCUMULATION_STEPS == 0 or (i + 1) == len(pbar):\n",
        "                            scaler.unscale_(optimizer)\n",
        "                            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "                            \n",
        "                            scaler.step(optimizer)\n",
        "                            scaler.update()\n",
        "                            optimizer.zero_grad(set_to_none=True)\n",
        "                        \n",
        "                running_loss += (loss.item() * ACCUMULATION_STEPS) * rgb_inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "                batch_loss = loss.item() * ACCUMULATION_STEPS\n",
        "                batch_acc = torch.sum(preds == labels.data).double() / rgb_inputs.size(0)\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f'{batch_loss:.4f}',\n",
        "                    'acc': f'{batch_acc:.4f}'\n",
        "                })\n",
        "                \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "            \n",
        "            # Track history\n",
        "            if phase == 'train':\n",
        "                train_losses.append(epoch_loss)\n",
        "                train_accs.append(epoch_acc.item())\n",
        "            else:  # validation phase\n",
        "                val_losses.append(epoch_loss)\n",
        "                val_accs.append(epoch_acc.item())\n",
        "                scheduler.step(epoch_loss)\n",
        "                \n",
        "                # Keep best model\n",
        "                if epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    epochs_no_improve = 0\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    \n",
        "                # Early stop check\n",
        "                if epochs_no_improve >= patience:\n",
        "                    print(f'\\nEarly stopping triggered after epoch {epoch}')\n",
        "                    print(f'Best validation accuracy: {best_acc:.4f}')\n",
        "                    model.load_state_dict(best_model_wts)\n",
        "                    return model, train_losses, val_losses, train_accs, val_accs\n",
        "                    \n",
        "            torch.cuda.empty_cache()\n",
        "                    \n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f'\\nCurrent learning rate: {current_lr:.2e}\\n')\n",
        "        \n",
        "    # Training complete\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "    \n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_losses, val_losses, train_accs, val_accs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training the model\n",
        "print(\"Starting training...\")\n",
        "model_ft, train_losses, val_losses, train_accs, val_accs = train_model(\n",
        "    model, criterion, optimizer, scheduler, num_epochs=num_epochs, patience=patience\n",
        ")\n",
        "\n",
        "# Plot learning curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Loss curves\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy curves\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(val_accs, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature extraction function\n",
        "def extract_features(model, dataloader, device):\n",
        "    \"\"\"Extract features from the two-stream network\"\"\"\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for rgb_inputs, vessel_inputs, batch_labels in tqdm(dataloader, desc='Extracting features'):\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "            rgb_inputs = rgb_inputs.to(device)\n",
        "            vessel_inputs = vessel_inputs.to(device)\n",
        "            \n",
        "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                batch_features = model(rgb_inputs, vessel_inputs)\n",
        "            \n",
        "            features.append(batch_features.cpu().numpy())\n",
        "            labels.extend(batch_labels.numpy())\n",
        "            \n",
        "            # Clean up memory\n",
        "            del rgb_inputs, vessel_inputs, batch_features\n",
        "            \n",
        "    return np.vstack(features), np.array(labels)\n",
        "\n",
        "# Initialize feature extraction model\n",
        "print(\"Creating feature extraction model...\")\n",
        "feature_model = TwoStreamNetwork(num_classes=num_classes, feature_extraction=True)\n",
        "feature_model = feature_model.to(device)\n",
        "\n",
        "# Load pre-trained weights\n",
        "if os.path.exists('best_swin_model.pth'):\n",
        "    print(\"Loading pre-trained weights...\")\n",
        "    checkpoint = torch.load('best_swin_model.pth')\n",
        "    feature_model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "\n",
        "# Extract features from datasets\n",
        "print(\"Extracting features...\")\n",
        "train_features, train_labels = extract_features(feature_model, dataloaders['train'], device)\n",
        "val_features, val_labels = extract_features(feature_model, dataloaders['val'], device)\n",
        "test_features, test_labels = extract_features(feature_model, dataloaders['test'], device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Scale features\n",
        "print(\"Scaling features...\")\n",
        "scaler = StandardScaler()\n",
        "train_features_scaled = scaler.fit_transform(train_features)\n",
        "val_features_scaled = scaler.transform(val_features)\n",
        "test_features_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Clean up memory\n",
        "del train_features, val_features, test_features\n",
        "\n",
        "# Train XGBoost classifier\n",
        "print(\"Training XGBoost classifier...\")\n",
        "xgb_classifier = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor')\n",
        "grid_search = GridSearchCV(\n",
        "    xgb_classifier, \n",
        "    xgb_params, \n",
        "    cv=3, \n",
        "    n_jobs=1, \n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit XGBoost with early stopping\n",
        "print(\"Fitting XGBoost...\")\n",
        "grid_search.fit(\n",
        "    train_features_scaled, \n",
        "    train_labels,\n",
        "    eval_set=[(val_features_scaled, val_labels)],\n",
        "    early_stopping_rounds=20,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Get best model\n",
        "best_xgb = grid_search.best_estimator_\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Evaluate model\n",
        "print(\"\\nEvaluating model...\")\n",
        "val_pred = best_xgb.predict(val_features_scaled)\n",
        "val_acc = np.mean(val_pred == val_labels)\n",
        "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
        "\n",
        "test_pred = best_xgb.predict(test_features_scaled)\n",
        "test_acc = np.mean(test_pred == test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Metrics\n",
        "print('\\nDetailed Classification Report:')\n",
        "print(classification_report(test_labels, test_pred, \n",
        "                          target_names=[f'Class {i}' for i in range(num_classes)],\n",
        "                          digits=4))\n",
        "\n",
        "print('\\nConfusion Matrix:')\n",
        "cm = confusion_matrix(test_labels, test_pred)\n",
        "print(cm)\n",
        "\n",
        "# Per-class accuracy\n",
        "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
        "for i, acc in enumerate(class_accuracy):\n",
        "    print(f'Class {i} Accuracy: {acc:.4f}')\n",
        "\n",
        "# Save ensemble model\n",
        "save_path = f'ensemble_model_{test_acc:.4f}.pkl'\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'feature_model_state': feature_model.state_dict(),\n",
        "        'xgboost_model': best_xgb,\n",
        "        'scaler': scaler,\n",
        "        'test_acc': test_acc,\n",
        "        'best_params': grid_search.best_params_\n",
        "    }, f)\n",
        "print(f'\\nEnsemble model saved to {save_path}')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
